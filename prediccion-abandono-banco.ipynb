{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de Abandono de Clientes en Beta Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contenido <a id='back'></a>\n",
    "\n",
    "* [Introducción](#intro)\n",
    "* [Objetivos](#obj)\n",
    "* [Etapa 1. Descripción de los datos](#data_review)\n",
    "* [Etapa 2. Preprocesamiento de datos](#data_preprocessing)\n",
    "* [Etapa 3. Desarrollo de modelos](#modelo)\n",
    "* [Conclusiones](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción <a id='intro'></a>\n",
    "Beta Bank, una institución financiera, ha estado experimentando una pérdida constante de clientes mes a mes. Los banqueros han identificado que retener a los clientes existentes es significativamente más económico que adquirir nuevos. Con el fin de mitigar esta pérdida, Beta Bank ha decidido desarrollar un modelo de machine learning para predecir si un cliente dejará el banco en el futuro cercano.\n",
    "\n",
    "## Objetivos: <a id='obj'></a>\n",
    "Crear un modelo de machine learning que prediga con precisión el abandono de clientes en Beta Bank. El modelo deberá alcanzar un valor F1 mínimo de 0.59. Además, se evaluará la métrica ROC-AUC para proporcionar una visión más completa del rendimiento del modelo.\n",
    "\n",
    "## Etapas:\n",
    "El proyecto consistirá en tres etapas:\n",
    " 1. Descripción de los datos.\n",
    " 2. Preprocesamiento de datos.\n",
    " 3. Desarrollo de modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1. Descripción de los datos <a id='data_review'></a>\n",
    "\n",
    "El conjunto de datos proporcionado contiene información sobre el comportamiento pasado de los clientes de Beta Bank, incluyendo características demográficas, financieras y de comportamiento. Las principales características del conjunto de datos son:\n",
    "\n",
    "RowNumber: Índice del conjunto de datos.\n",
    "\n",
    "CustomerId: Identificador único del cliente.\n",
    "\n",
    "Surname: Apellido del cliente.\n",
    "\n",
    "CreditScore: Puntaje de crédito del cliente.\n",
    "\n",
    "Geography: País de residencia del cliente.\n",
    "\n",
    "Gender: Género del cliente.\n",
    "\n",
    "Age: Edad del cliente.\n",
    "\n",
    "Tenure: Duración de la relación del cliente con el banco (en años).\n",
    "\n",
    "Balance: Saldo de la cuenta del cliente.\n",
    "\n",
    "NumOfProducts: Número de productos bancarios utilizados por el cliente.\n",
    "\n",
    "HasCrCard: Indicador de si el cliente tiene una tarjeta de crédito (1 - sí, 0 - no).\n",
    "\n",
    "IsActiveMember: Indicador de si el cliente es un miembro activo (1 - sí, 0 - no).\n",
    "\n",
    "EstimatedSalary: Salario estimado del cliente.\n",
    "\n",
    "Exited: Indicador de si el cliente ha dejado el banco (1 - sí, 0 - no)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2. Preprocesamiento de datos <a id='data_preprocessing)'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos librerias necesarias para el proyecto\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploracion Inicial de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Churn.csv\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que la columna Tenure tiene valores nulos, tambien podemos diferenciar las categorias mediante el tipo para su posterior analisis. Escogeremos la mediana para completar los valores nulos. Adicionalmente agregaremos dummys para las variables categoricas, que serian Geography y Gender. Tambien eliminamos la columna object que seria surname ya que no aporta al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   CreditScore        10000 non-null  int64  \n",
      " 1   Age                10000 non-null  int64  \n",
      " 2   Tenure             10000 non-null  float64\n",
      " 3   Balance            10000 non-null  float64\n",
      " 4   NumOfProducts      10000 non-null  int64  \n",
      " 5   HasCrCard          10000 non-null  int64  \n",
      " 6   IsActiveMember     10000 non-null  int64  \n",
      " 7   EstimatedSalary    10000 non-null  float64\n",
      " 8   Exited             10000 non-null  int64  \n",
      " 9   Geography_Germany  10000 non-null  bool   \n",
      " 10  Geography_Spain    10000 non-null  bool   \n",
      " 11  Gender_Male        10000 non-null  bool   \n",
      "dtypes: bool(3), float64(3), int64(6)\n",
      "memory usage: 732.6 KB\n"
     ]
    }
   ],
   "source": [
    "#rellenamos los valores nulos con la mediana y eliminamos el tipo object\n",
    "data[\"Tenure\"].fillna(data[\"Tenure\"].median(), inplace=True)\n",
    "data = data.drop(['Surname','RowNumber','CustomerId'], axis=1)\n",
    "\n",
    "#creamos dummys a las variables categoricas\n",
    "data = pd.get_dummies(data, columns=[\"Geography\",\"Gender\"], drop_first=True)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n",
      "0    7963\n",
      "1    2037\n",
      "Name: count, dtype: int64\n",
      "Exited\n",
      "0    0.7963\n",
      "1    0.2037\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_counts = data['Exited'].value_counts()\n",
    "class_proportions = class_counts / len(data)\n",
    "\n",
    "print(class_counts)\n",
    "print(class_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 3. Desarrollo de modelos <a id='modelo'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.4970711297071129, ROC = 0.7582673497904052\n",
      "Acurracy score = 0.6995\n"
     ]
    }
   ],
   "source": [
    "features = data.drop(['Exited'], axis=1)\n",
    "target = data['Exited']\n",
    "\n",
    "#separamos el dataset en 60% entrenamiento, 20% validacion y el resto en prueba\n",
    "\n",
    "features_train, features_remaining, target_train, target_remaining = train_test_split(features, target, test_size=0.4,random_state=12345)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_remaining, target_remaining, test_size=0.5,random_state=12345)\n",
    "\n",
    "#entrenamos el primer modelo  \n",
    "model = LogisticRegression(random_state=12345,solver=\"liblinear\", class_weight='balanced')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "\n",
    "print(f'F1 = {f1_score(target_valid, predicted_valid)}, ROC = {roc_auc_score(target_valid, model.predict_proba(features_valid)[:, 1])}')\n",
    "print(f'Acurracy score = {accuracy_score(target_valid, predicted_valid)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nos salio el F1 por debajo de la metrica a pesar de haber equilibrado los pesos, debemos intentar probar otro modelo. Utilizando otro modelo de ML como el RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.5718701700154559, ROC = 0.8382188375201882\n",
      "Acurracy score = 0.8615\n"
     ]
    }
   ],
   "source": [
    "#entrenamos un segundo modelo\n",
    "model_tree = RandomForestClassifier(random_state=12345, class_weight='balanced')\n",
    "model_tree.fit(features_train, target_train)\n",
    "predicted_valid_tree = model_tree.predict(features_valid)\n",
    "\n",
    "print(f'F1 = {f1_score(target_valid, predicted_valid_tree)}, ROC = {roc_auc_score(target_valid, model_tree.predict_proba(features_valid)[:, 1])}')\n",
    "print(f'Acurracy score = {accuracy_score(target_valid, predicted_valid_tree)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que el modelo tree esta funcionando mejor que el modelo de regresion logistica, ahora ajustaremos los hiperparametros para seguir mejorando el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 100, max_depth: 10, F1: 0.6159420289855072, ROC: 0.8525320743532202\n",
      "n_estimators: 100, max_depth: 20, F1: 0.5538461538461539, ROC: 0.8385583326780347\n",
      "n_estimators: 100, max_depth: 30, F1: 0.5718701700154559, ROC: 0.8382188375201882\n",
      "n_estimators: 200, max_depth: 10, F1: 0.6161251504211794, ROC: 0.8545418251985554\n",
      "n_estimators: 200, max_depth: 20, F1: 0.5564142194744978, ROC: 0.8426209328631312\n",
      "n_estimators: 200, max_depth: 30, F1: 0.56793893129771, ROC: 0.8408932125164077\n",
      "n_estimators: 300, max_depth: 10, F1: 0.6148325358851675, ROC: 0.8548881253818376\n",
      "n_estimators: 300, max_depth: 20, F1: 0.5766871165644172, ROC: 0.8436439550202941\n",
      "n_estimators: 300, max_depth: 30, F1: 0.5788667687595712, ROC: 0.842709398193795\n",
      "Mejor F1: 0.6161251504211794, Mejor ROC-AUC: 0.8545418251985554, con hiperparámetros: {'n_estimators': 200, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "#ajustamos hiperparametros\n",
    "n_estimators_values = [100, 200, 300]\n",
    "max_depth_values = [10, 20, 30]\n",
    "\n",
    "best_f1 = 0\n",
    "best_roc_auc = 0\n",
    "best_params = {}\n",
    "\n",
    "for n_estimators in n_estimators_values:\n",
    "    for max_depth in max_depth_values:\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=12345, class_weight='balanced')\n",
    "    \n",
    "        model.fit(features_train, target_train)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "\n",
    "        f1 = f1_score(target_valid, predicted_valid)\n",
    "        roc_auc = roc_auc_score(target_valid, model.predict_proba(features_valid)[:, 1])\n",
    "    \n",
    "        print(f'n_estimators: {n_estimators}, max_depth: {max_depth}, F1: {f1}, ROC: {roc_auc}')\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_roc_auc = roc_auc\n",
    "            best_params = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "\n",
    "print(f'Mejor F1: {best_f1}, Mejor ROC-AUC: {best_roc_auc}, con hiperparámetros: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.5880758807588076, ROC = 0.8435585141453796\n",
      "Acurracy score = 0.848\n"
     ]
    }
   ],
   "source": [
    "#aplicando tecnica de sobremuestreo al modelo 2\n",
    "def upsample (features, target, repeat):\n",
    "    features_zeros = features_train[target_train == 0]\n",
    "    features_ones = features_train[target_train == 1]\n",
    "    target_zeros = target_train[target_train == 0]\n",
    "    target_ones = target_train[target_train == 1]\n",
    "\n",
    "    arg1 = pd.concat([features_zeros]+[features_ones]*repeat)\n",
    "    arg2 = pd.concat([target_zeros]+[target_ones]*repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(arg1, arg2, random_state=12345)\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 10)\n",
    "\n",
    "#entrenamos el modelo con el sobremuestreo\n",
    "\n",
    "model_tree_upsampled = RandomForestClassifier(random_state=12345)\n",
    "model_tree_upsampled.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid_tree_upsampled = model_tree_upsampled.predict(features_valid)\n",
    "\n",
    "print(f'F1 = {f1_score(target_valid, predicted_valid_tree_upsampled)}, ROC = {roc_auc_score(target_valid, model_tree_upsampled.predict_proba(features_valid)[:, 1])}')\n",
    "print(f'Acurracy score = {accuracy_score(target_valid, predicted_valid_tree_upsampled)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la tecnica del sobremuestreo, se obtiene un F1 menor por el cual concluimos que el metodo que utilizaremos para la prueba final del mejor modelo seria el class_weight ='balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.27081581160639195, ROC = 0.8545418251985554\n",
      "Acurracy score = 0.686\n"
     ]
    }
   ],
   "source": [
    "#prueba final con el conjunto de prueba\n",
    "model_final = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=12345, class_weight='balanced')\n",
    "model_final.fit(features_train, target_train)\n",
    "predicted_valid_final = model.predict(features_test)\n",
    "\n",
    "print(f'F1 = {f1_score(target_valid, predicted_valid_final)}, ROC = {roc_auc_score(target_valid, model_final.predict_proba(features_valid)[:, 1])}')\n",
    "print(f'Acurracy score = {accuracy_score(target_test, predicted_valid_final)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a id='end'></a>\n",
    "\n",
    "En este proyecto, se desarrolló un modelo de machine learning para predecir el abandono de clientes en Beta Bank. \n",
    "\n",
    "El objetivo fue crear un modelo que alcanzara un valor F1 mínimo de 0.59 y una alta métrica ROC-AUC.\n",
    "\n",
    "El modelo final, utilizando RandomForestClassifier con n_estimators = 200 y max_depth = 10, alcanzó un valor F1 de 0.616 y un ROC-AUC de 0.854.\n",
    "\n",
    "Estos resultados superan el umbral mínimo requerido para el valor F1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
